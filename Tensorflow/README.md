## Folder Setup

## Regularization - Reducing Overfitting
The purpose of adding regularization techniques, is to reduce the model from overfitting. Some techniques used are; reduce model capacity, l2 regularization, dropout, early stopping and data augmentation.
Some of those techniques can be found in:
1. l2 regularization: 4_CNN_functional.py
2. dropout: 4_CNN_functional.py

## Model Subclassing
The purpose of model subclassing is to create a class which is reusable across layers. The code can be found at 9_model_subclassing.py

## Custom Model, Dense Layer and Relu
Can be found in 10_custom_layers.py

## Pretrained, Fine Tuning and Layers Freezing
The purpose of Layer Freezing is to use model layers without training them from scratch. This allows fast training than training them from scratch. The codes can be found in 12_pretrained_model.py .
It also includes how to fine tune models from tensorflow hub, keras, and other sources like huggingface and github. 

## Course Sources:
1. TensorFlow 2.0 Beginner Tutorials by Aladdin Persson : https://youtube.com/playlist?list=PLhhyoLH6IjfxVOdVC1P1L5z5azs0XjMsb&si=bUcpLOQsi3zU1L5A
 
